import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from PIL import Image
import os
import random
from pathlib import Path

def validate_model_performance():
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –≤—ã—Å–æ–∫–∏—Ö –º–µ—Ç—Ä–∏–∫"""
    
    print("üîç –í–ê–õ–ò–î–ê–¶–ò–Ø –ú–û–î–ï–õ–ò: –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–û–í–ï–†–ù–û–°–¢–ò –ú–ï–¢–†–ò–ö")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint
    checkpoint_path = 'training_results/finetuned_best_model.pth'
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    
    print("üìä –ê–ù–ê–õ–ò–ó –°–û–•–†–ê–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–•:")
    print(f"üéØ F1 Score: {checkpoint.get('best_f1', 'N/A'):.6f}")
    print(f"üìÖ –≠–ø–æ—Ö–∞: {checkpoint.get('epoch', 'N/A')}")
    
    # 1. –ê–Ω–∞–ª–∏–∑ Confusion Matrix
    if 'all_labels' in checkpoint and 'all_preds_improved' in checkpoint:
        print("\nüìä –ê–ù–ê–õ–ò–ó CONFUSION MATRIX:")
        
        y_true = checkpoint['all_labels']
        y_pred = checkpoint['all_preds_improved']
        
        print(f"üìà –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(y_true)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # Confusion Matrix
        cm = confusion_matrix(y_true, y_pred)
        class_names = ['No Damage', 'Minor Damage', 'Major Damage']
        
        print("\nüîç Confusion Matrix:")
        print("     Predicted:")
        print("        0    1    2")
        for i, row in enumerate(cm):
            print(f"True {i}: {row}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º
        print("\nüìä –ê–ù–ê–õ–ò–ó –ü–û –ö–õ–ê–°–°–ê–ú:")
        total_samples = len(y_true)
        unique, counts = np.unique(y_true, return_counts=True)
        
        for i, (class_idx, count) in enumerate(zip(unique, counts)):
            percentage = (count / total_samples) * 100
            print(f"  {class_names[class_idx]}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤ ({percentage:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: –∞–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
        print("\nüîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–û–ß–ù–û–°–¢–¨ –ü–û –ö–õ–ê–°–°–ê–ú:")
        for i in range(len(class_names)):
            true_positives = cm[i, i]
            total_true = cm[i, :].sum()
            total_predicted = cm[:, i].sum()
            
            precision = true_positives / total_predicted if total_predicted > 0 else 0
            recall = true_positives / total_true if total_true > 0 else 0
            
            print(f"  {class_names[i]}:")
            print(f"    Precision: {precision:.4f}")
            print(f"    Recall: {recall:.4f}")
            print(f"    –ò—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ: {true_positives}/{total_true}")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Confusion Matrix
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=class_names, yticklabels=class_names)
        plt.title('Confusion Matrix - Fine-tuned Model', fontsize=14, fontweight='bold')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig('training_results/confusion_matrix_validation.png', dpi=300, bbox_inches='tight')
        print(f"üìä Confusion matrix —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: training_results/confusion_matrix_validation.png")
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        print("\n‚öñÔ∏è –ü–†–û–í–ï–†–ö–ê –î–ò–°–ë–ê–õ–ê–ù–°–ê –ö–õ–ê–°–°–û–í:")
        class_distribution = np.bincount(y_true)
        max_class = np.max(class_distribution)
        min_class = np.min(class_distribution)
        imbalance_ratio = max_class / min_class
        
        print(f"üìä –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {class_distribution}")
        print(f"‚öñÔ∏è –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞: {imbalance_ratio:.2f}")
        
        if imbalance_ratio > 10:
            print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤!")
            print("   –í—ã—Å–æ–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤—ã–º–∏")
        elif imbalance_ratio > 3:
            print("‚ö° –£–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤")
        else:
            print("‚úÖ –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤")
    
    # 3. –ê–Ω–∞–ª–∏–∑ –∫—Ä–∏–≤–æ–π –æ–±—É—á–µ–Ω–∏—è
    if 'val_f1_scores' in checkpoint:
        print("\nüìà –ê–ù–ê–õ–ò–ó –ö–†–ò–í–û–ô –û–ë–£–ß–ï–ù–ò–Ø:")
        val_f1_scores = checkpoint['val_f1_scores']
        
        print(f"üìä –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: {len(val_f1_scores)}")
        print(f"üéØ –ù–∞—á–∞–ª—å–Ω—ã–π F1: {val_f1_scores[0]:.4f}")
        print(f"üèÜ –§–∏–Ω–∞–ª—å–Ω—ã–π F1: {val_f1_scores[-1]:.4f}")
        print(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ: {val_f1_scores[-1] - val_f1_scores[0]:.4f}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        if len(val_f1_scores) > 5:
            last_5 = val_f1_scores[-5:]
            if all(score >= 0.9 for score in last_5):
                print("‚ö†Ô∏è –í–û–ó–ú–û–ñ–ù–û–ï –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï: F1 > 0.9 –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —ç–ø–æ—Ö")
            elif np.std(last_5) < 0.01:
                print("‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å")
            else:
                print("üìä –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∏–≤–æ–π –æ–±—É—á–µ–Ω–∏—è
        plt.figure(figsize=(12, 6))
        plt.plot(range(1, len(val_f1_scores) + 1), val_f1_scores, 'b-o', linewidth=2, markersize=6)
        plt.title('F1 Score –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è', fontsize=14, fontweight='bold')
        plt.xlabel('–≠–ø–æ—Ö–∞')
        plt.ylabel('F1 Score')
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
        plt.axhline(y=0.9, color='green', linestyle='--', alpha=0.7, label='–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (0.9)')
        plt.axhline(y=0.8, color='orange', linestyle='--', alpha=0.7, label='–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (0.8)')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('training_results/learning_curve_validation.png', dpi=300, bbox_inches='tight')
        print(f"üìà –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: training_results/learning_curve_validation.png")
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ inference
    if 'inference_params' in checkpoint:
        print("\nüîß –ü–ê–†–ê–ú–ï–¢–†–´ INFERENCE:")
        params = checkpoint['inference_params']
        for key, value in params.items():
            print(f"  {key}: {value}")
    
    return checkpoint

def create_model_architecture():
    """–í–æ—Å—Å–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤"""
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
    class DamageClassifier(nn.Module):
        def __init__(self, num_classes=3):
            super(DamageClassifier, self).__init__()
            self.backbone = models.resnet50(weights=None)
            self.backbone.fc = nn.Identity()  # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
            self.classifier = nn.Sequential(
                nn.Linear(2048, 512),
                nn.ReLU(),
                nn.BatchNorm1d(512),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.BatchNorm1d(256),
                nn.Dropout(0.2),
                nn.Linear(256, num_classes)
            )
        
        def forward(self, x):
            features = self.backbone(x)
            return self.classifier(features)
    
    return DamageClassifier()

def test_model_on_sample_images():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ–±—Ä–∞–∑—Ü–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    
    print("\nüñºÔ∏è –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –û–ë–†–ê–ó–¶–ê–• –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:")
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        model = create_model_architecture()
        checkpoint = torch.load('training_results/finetuned_best_model.pth', map_location='cpu', weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        test_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # –ü–æ–∏—Å–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        test_dirs = [
            "data/integrated_multiclass_dataset/valid",
            "data/car_damage.v8i.multiclass/valid", 
            "data/Car damages.v3i.multiclass/valid"
        ]
        
        class_names = ['No Damage', 'Minor Damage', 'Major Damage']
        test_results = []
        
        for test_dir in test_dirs:
            if os.path.exists(test_dir):
                print(f"\nüìÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤: {test_dir}")
                
                for class_name in class_names:
                    class_dir = os.path.join(test_dir, class_name.lower().replace(' ', '_'))
                    if os.path.exists(class_dir):
                        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                        
                        if len(images) > 0:
                            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                            test_images = random.sample(images, min(3, len(images)))
                            
                            for img_name in test_images:
                                img_path = os.path.join(class_dir, img_name)
                                
                                try:
                                    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                    image = Image.open(img_path).convert('RGB')
                                    input_tensor = test_transform(image).unsqueeze(0)
                                    
                                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                                    with torch.no_grad():
                                        outputs = model(input_tensor)
                                        probabilities = torch.softmax(outputs, dim=1)
                                        predicted_class = torch.argmax(outputs, dim=1).item()
                                        confidence = probabilities[0][predicted_class].item()
                                    
                                    true_class = class_names.index(class_name)
                                    is_correct = predicted_class == true_class
                                    
                                    result = {
                                        'image': img_name,
                                        'true_class': class_name,
                                        'predicted_class': class_names[predicted_class],
                                        'confidence': confidence,
                                        'correct': is_correct
                                    }
                                    test_results.append(result)
                                    
                                    status = "‚úÖ" if is_correct else "‚ùå"
                                    print(f"  {status} {img_name}: {class_name} ‚Üí {class_names[predicted_class]} ({confidence:.3f})")
                                    
                                except Exception as e:
                                    print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {img_name}: {e}")
                break  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if test_results:
            correct_predictions = sum(1 for r in test_results if r['correct'])
            total_predictions = len(test_results)
            accuracy = correct_predictions / total_predictions
            
            print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—Ä–∞–∑—Ü–∞—Ö: {accuracy:.4f} ({correct_predictions}/{total_predictions})")
            print(f"üìà –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {np.mean([r['confidence'] for r in test_results]):.4f}")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º
            for class_name in class_names:
                class_results = [r for r in test_results if r['true_class'] == class_name]
                if class_results:
                    class_accuracy = sum(1 for r in class_results if r['correct']) / len(class_results)
                    print(f"  {class_name}: {class_accuracy:.4f} ({len(class_results)} –æ–±—Ä–∞–∑—Ü–æ–≤)")
        
        return test_results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return []

def generate_validation_report():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    
    print("\nüìã –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò:")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    checkpoint = torch.load('training_results/finetuned_best_model.pth', map_location='cpu', weights_only=False)
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã
    conclusions = []
    
    # –ê–Ω–∞–ª–∏–∑ F1 score
    f1_score = checkpoint.get('best_f1', 0)
    if f1_score > 0.95:
        conclusions.append("‚ö†Ô∏è F1 > 0.95: –í–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ")
    elif f1_score > 0.9:
        conclusions.append("‚úÖ F1 > 0.9: –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
    elif f1_score > 0.8:
        conclusions.append("‚úÖ F1 > 0.8: –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
    else:
        conclusions.append("üìä F1 < 0.8: –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è")
    
    # –ê–Ω–∞–ª–∏–∑ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    epoch = checkpoint.get('epoch', 0)
    if epoch > 15:
        conclusions.append("üìà –û–±—É—á–µ–Ω–∏–µ > 15 —ç–ø–æ—Ö: –ú–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å—Ö–æ–¥–∏—Ç—Å—è")
    
    # –ê–Ω–∞–ª–∏–∑ Damage Recall
    damage_recall = checkpoint.get('damage_recall_imp', 0)
    if damage_recall > 0.95:
        conclusions.append("üéØ Damage Recall > 95%: –û—Ç–ª–∏—á–Ω–æ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è")
    
    # –ê–Ω–∞–ª–∏–∑ Major Recall  
    major_recall = checkpoint.get('major_recall_imp', 0)
    if major_recall > 0.85:
        conclusions.append("üîç Major Recall > 85%: –•–æ—Ä–æ—à–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è")
    
    print("\nüéØ –í–´–í–û–î–´:")
    for conclusion in conclusions:
        print(f"  {conclusion}")
    
    print(f"\nüìä –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if f1_score > 0.92:
        print("  ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É")
        print("  üìã –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        print("  üîç –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É –Ω–∞ edge cases")
    else:
        print("  üìà –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        print("  üîÑ –í–æ–∑–º–æ–∂–Ω–æ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")

if __name__ == "__main__":
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        checkpoint = validate_model_performance()
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ–±—Ä–∞–∑—Ü–∞—Ö
        test_results = test_model_on_sample_images()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        generate_validation_report()
        
        plt.show()
        
        print("\n‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("üìä –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ training_results/")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()