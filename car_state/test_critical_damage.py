import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import random
from pathlib import Path

def create_correct_model_architecture():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –∏–∑ finetune_existing_model.py"""
    
    class ImprovedDamageClassifier(nn.Module):
        def __init__(self, num_classes=3, dropout_rate=0.3):
            super(ImprovedDamageClassifier, self).__init__()
            
            # Backbone: ResNet50
            self.backbone = models.resnet50(weights=None)
            self.backbone.fc = nn.Identity()  # Remove the final layer
            
            # Enhanced classifier with more layers and regularization
            self.classifier = nn.Sequential(
                nn.Linear(2048, 1024),
                nn.ReLU(),
                nn.BatchNorm1d(1024),
                nn.Dropout(dropout_rate),
                
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.BatchNorm1d(512),
                nn.Dropout(dropout_rate * 0.7),
                
                nn.Linear(512, num_classes)
            )
        
        def forward(self, x):
            features = self.backbone(x)
            return self.classifier(features)
    
    return ImprovedDamageClassifier()

def load_both_models():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    
    print("üîç –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô –î–õ–Ø –°–†–ê–í–ù–ï–ù–ò–Ø:")
    print("=" * 50)
    
    models_info = {}
    
    # 1. –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (F1=0.7383)
    base_path = "training_results/best_model.pth"
    if os.path.exists(base_path):
        try:
            base_checkpoint = torch.load(base_path, map_location='cpu', weights_only=False)
            base_model = create_correct_model_architecture()
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å state_dict
            if 'model_state_dict' in base_checkpoint:
                try:
                    base_model.load_state_dict(base_checkpoint['model_state_dict'])
                    base_model.eval()
                    models_info['base'] = {
                        'model': base_model,
                        'f1': base_checkpoint.get('val_f1', 0.7383),
                        'name': '–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å'
                    }
                    print(f"‚úÖ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: F1={base_checkpoint.get('val_f1', 0.7383):.4f}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é: {e}")
    
    # 2. Fine-tuned –º–æ–¥–µ–ª—å (F1=0.944)
    finetuned_path = "training_results/finetuned_best_model.pth"
    if os.path.exists(finetuned_path):
        try:
            finetuned_checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
            finetuned_model = create_correct_model_architecture()
            
            if 'model_state_dict' in finetuned_checkpoint:
                try:
                    finetuned_model.load_state_dict(finetuned_checkpoint['model_state_dict'])
                    finetuned_model.eval()
                    models_info['finetuned'] = {
                        'model': finetuned_model,
                        'f1': finetuned_checkpoint.get('best_f1', 0.944),
                        'name': 'Fine-tuned –º–æ–¥–µ–ª—å'
                    }
                    print(f"‚úÖ Fine-tuned –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: F1={finetuned_checkpoint.get('best_f1', 0.944):.4f}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ fine-tuned –º–æ–¥–µ–ª–∏: {e}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å fine-tuned –º–æ–¥–µ–ª—å—é: {e}")
    
    return models_info

def find_severely_damaged_cars():
    """–ò—â–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–∏–ª—å–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –º–∞—à–∏–Ω –≤ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö"""
    
    print("\nüîç –ü–û–ò–°–ö –°–ò–õ–¨–ù–û –ü–û–í–†–ï–ñ–î–ï–ù–ù–´–• –ê–í–¢–û–ú–û–ë–ò–õ–ï–ô:")
    print("=" * 50)
    
    # –ü–æ–∏—Å–∫ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
    search_dirs = [
        "data/RoadAccident.v2i.multiclass/train/major_damage",
        "data/RoadAccident.v2i.multiclass/valid/major_damage", 
        "data/Car damages.v3i.multiclass/train",
        "data/Car damages.v3i.multiclass/valid",
        "data/integrated_multiclass_dataset/train/major_damage",
        "data/integrated_multiclass_dataset/valid/major_damage"
    ]
    
    severely_damaged_images = []
    
    for search_dir in search_dirs:
        if os.path.exists(search_dir):
            print(f"üìÅ –ü–æ–∏—Å–∫ –≤: {search_dir}")
            
            for file in os.listdir(search_dir):
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, —É–∫–∞–∑—ã–≤–∞—é—â–∏–º–∏ –Ω–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è
                    keywords = ['accident', 'crash', 'destroyed', 'wreck', 'severe', 'major', 'total', 'damage']
                    if any(keyword in file.lower() for keyword in keywords):
                        severely_damaged_images.append(os.path.join(search_dir, file))
            
            # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–æ–∫ major_damage
            if 'major_damage' in search_dir:
                images = [f for f in os.listdir(search_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                if images:
                    # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö
                    selected = random.sample(images, min(5, len(images)))
                    for img in selected:
                        img_path = os.path.join(search_dir, img)
                        if img_path not in severely_damaged_images:
                            severely_damaged_images.append(img_path)
    
    print(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(severely_damaged_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Å–µ—Ä—å–µ–∑–Ω—ã–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏")
    return severely_damaged_images

def test_on_severely_damaged_cars(models_info, test_images):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–∏–ª—å–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª—è—Ö"""
    
    print("\nüí• –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò –ü–û–í–†–ï–ñ–î–ï–ù–ù–´–• –ê–í–¢–û–ú–û–ë–ò–õ–Ø–•:")
    print("=" * 60)
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    class_names = ['No Damage', 'Minor Damage', 'Major Damage']
    results = {}
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    for model_key, model_info in models_info.items():
        results[model_key] = {
            'correct_major': 0,
            'predicted_no_damage': 0,
            'predicted_minor': 0,
            'predicted_major': 0,
            'total_tested': 0,
            'predictions': []
        }
    
    print(f"üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    
    for i, img_path in enumerate(test_images[:20]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(img_path).convert('RGB')
            input_tensor = test_transform(image).unsqueeze(0)
            
            print(f"\nüì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}: {os.path.basename(img_path)}")
            
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model_key, model_info in models_info.items():
                model = model_info['model']
                
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probabilities = torch.softmax(outputs, dim=1)
                    predicted_class = torch.argmax(outputs, dim=1).item()
                    confidence = probabilities[0][predicted_class].item()
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                results[model_key]['total_tested'] += 1
                results[model_key]['predictions'].append({
                    'image': os.path.basename(img_path),
                    'predicted_class': predicted_class,
                    'confidence': confidence,
                    'probabilities': probabilities[0].tolist()
                })
                
                if predicted_class == 0:  # No Damage - –ü–õ–û–•–û –¥–ª—è —Ä–∞–∑—Ä—É—à–µ–Ω–Ω–æ–π –º–∞—à–∏–Ω—ã!
                    results[model_key]['predicted_no_damage'] += 1
                    status = "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê"
                elif predicted_class == 1:  # Minor Damage - –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫–∞
                    results[model_key]['predicted_minor'] += 1
                    status = "‚ö†Ô∏è –ù–ï–î–û–û–¶–ï–ù–ö–ê"
                elif predicted_class == 2:  # Major Damage - –ø—Ä–∞–≤–∏–ª—å–Ω–æ!
                    results[model_key]['predicted_major'] += 1
                    results[model_key]['correct_major'] += 1
                    status = "‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û"
                
                print(f"  {model_info['name']}: {class_names[predicted_class]} ({confidence:.3f}) {status}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å {img_path}: {e}")
    
    return results

def analyze_critical_damage_detection(results, models_info):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è"""
    
    print("\nüìä –ê–ù–ê–õ–ò–ó –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –ü–û–í–†–ï–ñ–î–ï–ù–ò–ô:")
    print("=" * 60)
    
    for model_key, model_info in models_info.items():
        model_results = results[model_key]
        total = model_results['total_tested']
        
        if total == 0:
            continue
            
        print(f"\nüîπ {model_info['name']} (F1={model_info['f1']:.4f}):")
        print(f"   üìä –í—Å–µ–≥–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {total}")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        correct_major = model_results['correct_major']
        no_damage_errors = model_results['predicted_no_damage']
        minor_errors = model_results['predicted_minor']
        
        major_detection_rate = correct_major / total
        critical_error_rate = no_damage_errors / total  # –°–∞–º—ã–µ –æ–ø–∞—Å–Ω—ã–µ –æ—à–∏–±–∫–∏
        underestimation_rate = minor_errors / total
        
        print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–∞–∫ Major Damage: {correct_major}/{total} ({major_detection_rate:.1%})")
        print(f"   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò (No Damage): {no_damage_errors}/{total} ({critical_error_rate:.1%})")
        print(f"   ‚ö†Ô∏è –ù–µ–¥–æ–æ—Ü–µ–Ω–∫–∞ (Minor Damage): {minor_errors}/{total} ({underestimation_rate:.1%})")
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        if critical_error_rate == 0:
            print("   üèÜ –û–¢–õ–ò–ß–ù–û: –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫!")
        elif critical_error_rate < 0.1:
            print("   ‚úÖ –•–û–†–û–®–û: –ú–∞–ª–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")
        elif critical_error_rate < 0.3:
            print("   ‚ö†Ô∏è –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û: –ï—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏")
        else:
            print("   ‚ùå –ü–õ–û–•–û: –ú–Ω–æ–≥–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫!")
        
        if major_detection_rate > 0.8:
            print("   üéØ –û–¢–õ–ò–ß–ù–û: –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
        elif major_detection_rate > 0.6:
            print("   üìà –•–û–†–û–®–û: –ü—Ä–∏–µ–º–ª–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å")
        else:
            print("   üìâ –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø: –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å")

def create_comparison_visualization(results, models_info):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    model_names = []
    major_detection_rates = []
    critical_error_rates = []
    
    for model_key, model_info in models_info.items():
        model_results = results[model_key]
        total = model_results['total_tested']
        
        if total > 0:
            model_names.append(model_info['name'])
            major_detection_rates.append(model_results['correct_major'] / total)
            critical_error_rates.append(model_results['predicted_no_damage'] / total)
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –¢–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è Major Damage
    axes[0].bar(model_names, major_detection_rates, color=['#3498db', '#e74c3c'])
    axes[0].set_title('–¢–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', fontweight='bold')
    axes[0].set_ylabel('–î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
    axes[0].set_ylim(0, 1)
    
    for i, rate in enumerate(major_detection_rates):
        axes[0].text(i, rate + 0.02, f'{rate:.1%}', ha='center', fontweight='bold')
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (No Damage –¥–ª—è —Ä–∞–∑—Ä—É—à–µ–Ω–Ω—ã—Ö –º–∞—à–∏–Ω)
    axes[1].bar(model_names, critical_error_rates, color=['#3498db', '#e74c3c'])
    axes[1].set_title('–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n(—Ä–∞–∑—Ä—É—à–µ–Ω–Ω–∞—è –º–∞—à–∏–Ω–∞ ‚Üí "–Ω–µ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")', fontweight='bold')
    axes[1].set_ylabel('–î–æ–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫')
    axes[1].set_ylim(0, max(critical_error_rates) + 0.1 if critical_error_rates else 0.1)
    
    for i, rate in enumerate(critical_error_rates):
        axes[1].text(i, rate + 0.01, f'{rate:.1%}', ha='center', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('training_results/critical_damage_comparison.png', dpi=300, bbox_inches='tight')
    print(f"\nüìä –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: training_results/critical_damage_comparison.png")
    
    return fig

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print("üöóüí• –¢–ï–°–¢ –ù–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–û–í–†–ï–ñ–î–ï–ù–ò–Ø –ê–í–¢–û–ú–û–ë–ò–õ–ï–ô")
    print("=" * 70)
    print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑—Ä—É—à–µ–Ω–Ω—ã–µ –º–∞—à–∏–Ω—ã")
    print("(–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –¥–∞–≤–∞–ª–∞ 100% —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏)")
    print()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    models_info = load_both_models()
    
    if not models_info:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
        return
    
    # –ü–æ–∏—Å–∫ —Å–∏–ª—å–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
    severely_damaged_images = find_severely_damaged_cars()
    
    if not severely_damaged_images:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–∏–ª—å–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π")
        return
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    results = test_on_severely_damaged_cars(models_info, severely_damaged_images)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    analyze_critical_damage_detection(results, models_info)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    fig = create_comparison_visualization(results, models_info)
    plt.show()
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
    print("\nüéØ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´:")
    print("=" * 40)
    
    if 'finetuned' in results and results['finetuned']['total_tested'] > 0:
        finetuned_results = results['finetuned']
        critical_errors = finetuned_results['predicted_no_damage']
        total = finetuned_results['total_tested']
        correct_major = finetuned_results['correct_major']
        
        print(f"üìä Fine-tuned –º–æ–¥–µ–ª—å (F1=0.944):")
        print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è: {correct_major}/{total} ({correct_major/total:.1%})")
        print(f"   ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (—É–±–∏—Ç–∞—è –º–∞—à–∏–Ω–∞ ‚Üí '—Ü–µ–ª–∞—è'): {critical_errors}/{total} ({critical_errors/total:.1%})")
        
        if critical_errors == 0:
            print("\nüèÜ –ü–†–ï–í–û–°–•–û–î–ù–û! –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å –ù–ï –¥–µ–ª–∞–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫!")
            print("   –¢–µ–ø–µ—Ä—å –æ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑—Ä—É—à–µ–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏!")
        elif critical_errors/total < 0.1:
            print("\n‚úÖ –û–¢–õ–ò–ß–ù–û! –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π!")
        else:
            print("\n‚ö†Ô∏è –ï—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è, –Ω–æ –µ—â–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞ –Ω–∞–¥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–ª—É—á–∞—è–º–∏")
    
    print("\n‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")

if __name__ == "__main__":
    main()