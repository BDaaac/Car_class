import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import os

def analyze_critical_damage_from_checkpoint():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å fine-tuned –º–æ–¥–µ–ª–∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è"""
    
    print("üöóüí• –ê–ù–ê–õ–ò–ó –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –ü–û–í–†–ï–ñ–î–ï–ù–ò–ô")
    print("=" * 60)
    print("–ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    print()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ checkpoint
    finetuned_path = "training_results/finetuned_best_model.pth"
    if not os.path.exists(finetuned_path):
        print("‚ùå Fine-tuned –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    y_true = checkpoint.get('all_labels', [])
    y_pred_standard = checkpoint.get('all_preds_standard', [])
    y_pred_improved = checkpoint.get('all_preds_improved', [])
    y_probs = checkpoint.get('all_probs', [])
    
    if len(y_true) == 0:
        print("‚ùå –î–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ checkpoint")
        return
    
    print(f"üìä –î–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(y_true)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    class_names = ['No Damage', 'Minor Damage', 'Major Damage']
    
    # –ê–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    predictions = {
        'Standard': y_pred_standard,
        'Improved': y_pred_improved
    }
    
    f1_scores = {
        'Standard': checkpoint.get('f1_standard', 0),
        'Improved': checkpoint.get('f1_improved', 0)
    }
    
    print("\nüîç –ê–ù–ê–õ–ò–ó –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –û–®–ò–ë–û–ö:")
    print("=" * 50)
    
    for pred_type, y_pred in predictions.items():
        if len(y_pred) == 0:
            continue
            
        print(f"\nüîπ {pred_type} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (F1={f1_scores[pred_type]:.4f}):")
        
        # –§–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è –Ω–∞ —Å–ª—É—á–∞—è—Ö, –≥–¥–µ –∏—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å = Major Damage (–∫–ª–∞—Å—Å 2)
        major_damage_indices = np.array(y_true) == 2
        major_damage_true = np.array(y_true)[major_damage_indices]
        major_damage_pred = np.array(y_pred)[major_damage_indices]
        
        total_major = len(major_damage_true)
        print(f"   üìä –í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤ Major Damage: {total_major}")
        
        if total_major == 0:
            print("   ‚ö†Ô∏è –ù–µ—Ç —Å–ª—É—á–∞–µ–≤ Major Damage –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ")
            continue
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è Major Damage
        correct_major = np.sum(major_damage_pred == 2)  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –∫–∞–∫ Major
        predicted_minor = np.sum(major_damage_pred == 1)  # –ù–µ–¥–æ–æ—Ü–µ–Ω–∏–ª–∏ –∫–∞–∫ Minor
        predicted_no_damage = np.sum(major_damage_pred == 0)  # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê!
        
        print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ (Major ‚Üí Major): {correct_major}/{total_major} ({correct_major/total_major:.1%})")
        print(f"   ‚ö†Ô∏è –ù–µ–¥–æ–æ—Ü–µ–Ω–∫–∞ (Major ‚Üí Minor): {predicted_minor}/{total_major} ({predicted_minor/total_major:.1%})")
        print(f"   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê (Major ‚Üí No Damage): {predicted_no_damage}/{total_major} ({predicted_no_damage/total_major:.1%})")
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        critical_error_rate = predicted_no_damage / total_major
        correct_detection_rate = correct_major / total_major
        
        print(f"\n   üìà –¢–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {correct_detection_rate:.1%}")
        print(f"   üìâ –£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫: {critical_error_rate:.1%}")
        
        # –í–µ—Ä–¥–∏–∫—Ç
        if critical_error_rate == 0:
            print("   üèÜ –ü–†–ï–í–û–°–•–û–î–ù–û! –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫!")
        elif critical_error_rate < 0.05:
            print("   ‚úÖ –û–¢–õ–ò–ß–ù–û! –û—á–µ–Ω—å –º–∞–ª–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")
        elif critical_error_rate < 0.15:
            print("   üìà –•–û–†–û–®–û! –ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å –æ—à–∏–±–æ–∫")
        else:
            print("   ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø! –ú–Ω–æ–≥–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫")
        
        if correct_detection_rate > 0.85:
            print("   üéØ –û–¢–õ–ò–ß–ù–û! –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è")
        elif correct_detection_rate > 0.70:
            print("   üìà –•–û–†–û–®–û! –ü—Ä–∏–µ–º–ª–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å")
        else:
            print("   üìâ –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø! –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å")

def analyze_confidence_for_major_damage():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ major damage"""
    
    print("\nüéØ –ê–ù–ê–õ–ò–ó –£–í–ï–†–ï–ù–ù–û–°–¢–ò –ú–û–î–ï–õ–ò:")
    print("=" * 40)
    
    finetuned_path = "training_results/finetuned_best_model.pth"
    checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
    
    y_true = np.array(checkpoint.get('all_labels', []))
    y_probs = np.array(checkpoint.get('all_probs', []))
    y_pred_improved = np.array(checkpoint.get('all_preds_improved', []))
    
    if len(y_true) == 0 or len(y_probs) == 0:
        print("‚ùå –î–∞–Ω–Ω—ã–µ –æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª—É—á–∞–∏ Major Damage
    major_indices = y_true == 2
    major_probs = y_probs[major_indices]
    major_preds = y_pred_improved[major_indices]
    
    if len(major_probs) == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ Major Damage")
        return
    
    print(f"üìä –ê–Ω–∞–ª–∏–∑ {len(major_probs)} —Å–ª—É—á–∞–µ–≤ Major Damage:")
    
    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ Major Damage (–∏–Ω–¥–µ–∫—Å 2)
    major_class_probs = major_probs[:, 2]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    mean_confidence = np.mean(major_class_probs)
    median_confidence = np.median(major_class_probs)
    min_confidence = np.min(major_class_probs)
    max_confidence = np.max(major_class_probs)
    
    print(f"   üìà –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {mean_confidence:.3f}")
    print(f"   üìä –ú–µ–¥–∏–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {median_confidence:.3f}")
    print(f"   üìâ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {min_confidence:.3f}")
    print(f"   üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {max_confidence:.3f}")
    
    # –ê–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–µ–≤ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
    low_confidence_threshold = 0.5
    low_confidence_cases = major_class_probs < low_confidence_threshold
    num_low_confidence = np.sum(low_confidence_cases)
    
    print(f"\n‚ö†Ô∏è –°–ª—É—á–∞–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (<{low_confidence_threshold}): {num_low_confidence}/{len(major_probs)} ({num_low_confidence/len(major_probs):.1%})")
    
    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è Major Damage
    correct_major_preds = major_preds == 2
    accuracy_major = np.mean(correct_major_preds)
    
    print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ Major Damage: {accuracy_major:.1%}")
    
    # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
    wrong_preds = major_preds != 2
    if np.any(wrong_preds):
        wrong_as_no_damage = np.sum(major_preds == 0)
        wrong_as_minor = np.sum(major_preds == 1)
        
        print(f"‚ùå –û—à–∏–±–∫–∏:")
        print(f"   Major ‚Üí No Damage: {wrong_as_no_damage}")
        print(f"   Major ‚Üí Minor Damage: {wrong_as_minor}")

def create_critical_damage_visualization():
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π"""
    
    finetuned_path = "training_results/finetuned_best_model.pth"
    checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
    
    y_true = np.array(checkpoint.get('all_labels', []))
    y_pred_improved = np.array(checkpoint.get('all_preds_improved', []))
    
    if len(y_true) == 0:
        return
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é confusion matrix
    cm = confusion_matrix(y_true, y_pred_improved)
    class_names = ['No Damage', 'Minor Damage', 'Major Damage']
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. Confusion Matrix
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names, ax=axes[0])
    axes[0].set_title('Confusion Matrix\nFine-tuned Model (F1=0.944)', fontweight='bold')
    axes[0].set_ylabel('True Label')
    axes[0].set_xlabel('Predicted Label')
    
    # –í—ã–¥–µ–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
    axes[0].add_patch(plt.Rectangle((0, 2), 1, 1, fill=False, edgecolor='red', lw=3))
    axes[0].text(0.5, 2.5, '–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø\n–û–®–ò–ë–ö–ê!', ha='center', va='center', 
                color='red', fontweight='bold', fontsize=10)
    
    # 2. –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –¥–ª—è Major Damage
    major_indices = y_true == 2
    major_preds = y_pred_improved[major_indices]
    
    if len(major_preds) > 0:
        pred_counts = np.bincount(major_preds, minlength=3)
        pred_percentages = pred_counts / len(major_preds) * 100
        
        colors = ['red', 'orange', 'green']
        labels = ['‚Üí No Damage\n(–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê)', '‚Üí Minor Damage\n(–ù–µ–¥–æ–æ—Ü–µ–Ω–∫–∞)', '‚Üí Major Damage\n(–ü—Ä–∞–≤–∏–ª—å–Ω–æ)']
        
        bars = axes[1].bar(range(3), pred_percentages, color=colors, alpha=0.7)
        axes[1].set_title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∏—Å—Ç–∏–Ω–Ω—ã—Ö\nMajor Damage —Å–ª—É—á–∞–µ–≤', fontweight='bold')
        axes[1].set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç —Å–ª—É—á–∞–µ–≤')
        axes[1].set_xticks(range(3))
        axes[1].set_xticklabels(labels, rotation=0, fontsize=9)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, (bar, count, percent) in enumerate(zip(bars, pred_counts, pred_percentages)):
            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                        f'{count}\n({percent:.1f}%)', ha='center', va='bottom', 
                        fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('training_results/critical_damage_analysis.png', dpi=300, bbox_inches='tight')
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: training_results/critical_damage_analysis.png")
    
    return fig

def compare_with_baseline():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é"""
    
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ë–ê–ó–û–í–û–ô –ú–û–î–ï–õ–¨–Æ:")
    print("=" * 40)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
    base_path = "training_results/best_model.pth"
    if os.path.exists(base_path):
        base_checkpoint = torch.load(base_path, map_location='cpu', weights_only=False)
        base_f1 = base_checkpoint.get('val_f1', 0.7383)
        print(f"üìä –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å F1: {base_f1:.4f}")
    else:
        base_f1 = 0.7383
        print(f"üìä –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å F1: {base_f1:.4f} (–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)")
    
    # Fine-tuned –º–æ–¥–µ–ª—å
    finetuned_path = "training_results/finetuned_best_model.pth"
    finetuned_checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
    finetuned_f1 = finetuned_checkpoint.get('best_f1', 0.944)
    
    print(f"üöÄ Fine-tuned –º–æ–¥–µ–ª—å F1: {finetuned_f1:.4f}")
    
    improvement = finetuned_f1 - base_f1
    improvement_pct = (improvement / base_f1) * 100
    
    print(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ: +{improvement:.4f} (+{improvement_pct:.1f}%)")
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Major Damage Recall
    major_recall_std = finetuned_checkpoint.get('major_recall_std', 0)
    major_recall_imp = finetuned_checkpoint.get('major_recall_imp', 0)
    
    print(f"\nüîç Major Damage Recall:")
    print(f"   Standard: {major_recall_std:.1%}")
    print(f"   Improved: {major_recall_imp:.1%}")
    
    if major_recall_imp > 0.8:
        print("   üèÜ –ü–†–ï–í–û–°–•–û–î–ù–û! –û—Ç–ª–∏—á–Ω–æ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è")
    elif major_recall_imp > 0.7:
        print("   ‚úÖ –•–û–†–û–®–û! –ü—Ä–∏–µ–º–ª–µ–º–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
    else:
        print("   ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –°–ü–û–°–û–ë–ù–û–°–¢–ò –ú–û–î–ï–õ–ò –û–ë–ù–ê–†–£–ñ–ò–í–ê–¢–¨ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–û–í–†–ï–ñ–î–ï–ù–ò–Ø")
    print("=" * 80)
    print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–µ—à–µ–Ω–∞ –ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º '—É–±–∏—Ç—ã—Ö' –º–∞—à–∏–Ω –∫–∞–∫ —Ü–µ–ª—ã—Ö")
    print()
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
    analyze_critical_damage_from_checkpoint()
    
    # –ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    analyze_confidence_for_major_damage()
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
    compare_with_baseline()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    fig = create_critical_damage_visualization()
    plt.show()
    
    print("\nüéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:")
    print("=" * 30)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
    finetuned_path = "training_results/finetuned_best_model.pth"
    checkpoint = torch.load(finetuned_path, map_location='cpu', weights_only=False)
    
    y_true = np.array(checkpoint.get('all_labels', []))
    y_pred_improved = np.array(checkpoint.get('all_preds_improved', []))
    
    if len(y_true) > 0:
        major_indices = y_true == 2
        major_preds = y_pred_improved[major_indices]
        
        if len(major_preds) > 0:
            critical_errors = np.sum(major_preds == 0)  # Major ‚Üí No Damage
            total_major = len(major_preds)
            correct_major = np.sum(major_preds == 2)
            
            print(f"üìä –ò—Ç–æ–≥–∏ –¥–ª—è Major Damage ({total_major} —Å–ª—É—á–∞–µ–≤):")
            print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: {correct_major}/{total_major} ({correct_major/total_major:.1%})")
            print(f"   ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: {critical_errors}/{total_major} ({critical_errors/total_major:.1%})")
            
            if critical_errors == 0:
                print("\nüèÜ –†–ï–®–ï–ù–ò–ï –ù–ê–ô–î–ï–ù–û! –ú–æ–¥–µ–ª—å –±–æ–ª—å—à–µ –ù–ï –Ω–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑—Ä—É—à–µ–Ω–Ω—ã–µ –º–∞—à–∏–Ω—ã —Ü–µ–ª—ã–º–∏!")
                print("   –ü—Ä–æ–±–ª–µ–º–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º '—É–±–∏—Ç—ã—Ö' –º–∞—à–∏–Ω –∫–∞–∫ 100% —Ü–µ–ª—ã—Ö –†–ï–®–ï–ù–ê!")
            elif critical_errors/total_major < 0.05:
                print("\n‚úÖ –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï! –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ —Å—Ç–∞–ª–æ –æ—á–µ–Ω—å –º–∞–ª–æ!")
            elif critical_errors/total_major < 0.15:
                print("\nüìà –ï–°–¢–¨ –£–õ–£–ß–®–ï–ù–ò–Ø! –°–∏—Ç—É–∞—Ü–∏—è –ª—É—á—à–µ, –Ω–æ –º–æ–∂–Ω–æ –µ—â–µ —É–ª—É—á—à–∏—Ç—å")
            else:
                print("\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê –ß–ê–°–¢–ò–ß–ù–û –†–ï–®–ï–ù–ê. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞")
    
    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")

if __name__ == "__main__":
    main()