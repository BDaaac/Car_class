import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image, ImageFilter, ImageStat
import torch.nn.functional as F
import os
import sys
import numpy as np

class MulticlassDamageModel(nn.Module):
    def __init__(self, num_classes=3, dropout=0.6):
        super().__init__()
        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
        self.backbone.fc = nn.Identity()
        
        self.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(2048, 1024),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(1024),
            nn.Dropout(dropout * 0.5),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout * 0.25),
            nn.Linear(512, num_classes)
        )
        
    def forward(self, x):
        x = self.backbone.conv1(x)
        x = self.backbone.bn1(x)
        x = self.backbone.relu(x)
        x = self.backbone.maxpool(x)
        
        x = self.backbone.layer1(x)
        x = self.backbone.layer2(x)
        x = self.backbone.layer3(x)
        x = self.backbone.layer4(x)
        
        x = self.backbone.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        
        return x

def analyze_dirt_level_detailed(image):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    img_array = np.array(image)
    
    print("\\n" + "="*60)
    print("üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–ì–†–Ø–ó–ù–ï–ù–ù–û–°–¢–ò:")
    print("="*60)
    
    # 1. –¶–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    unique_colors_r = len(np.unique(img_array[:,:,0]))
    unique_colors_g = len(np.unique(img_array[:,:,1])) 
    unique_colors_b = len(np.unique(img_array[:,:,2]))
    color_diversity = (unique_colors_r + unique_colors_g + unique_colors_b) / 3
    
    print(f"üé® –¶–í–ï–¢–û–í–û–ï –†–ê–ó–ù–û–û–ë–†–ê–ó–ò–ï:")
    print(f"   ‚Ä¢ –ö—Ä–∞—Å–Ω—ã–π –∫–∞–Ω–∞–ª: {unique_colors_r} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤")
    print(f"   ‚Ä¢ –ó–µ–ª–µ–Ω—ã–π –∫–∞–Ω–∞–ª: {unique_colors_g} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤")
    print(f"   ‚Ä¢ –°–∏–Ω–∏–π –∫–∞–Ω–∞–ª: {unique_colors_b} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: {color_diversity:.1f}")
    
    # 2. –ö–æ–Ω—Ç—Ä–∞—Å—Ç
    gray = image.convert('L')
    contrast = ImageStat.Stat(gray).stddev[0]
    
    print(f"\\nüìä –ö–û–ù–¢–†–ê–°–¢:")
    print(f"   ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏: {contrast:.1f}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {'–í—ã—Å–æ–∫–∏–π' if contrast > 40 else '–°—Ä–µ–¥–Ω–∏–π' if contrast > 25 else '–ù–∏–∑–∫–∏–π'}")
    
    # 3. –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
    hsv = image.convert('HSV')
    hsv_array = np.array(hsv)
    saturation = np.mean(hsv_array[:,:,1])
    saturation_std = np.std(hsv_array[:,:,1])
    
    print(f"\\nüåà –ù–ê–°–´–©–ï–ù–ù–û–°–¢–¨:")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å: {saturation:.1f}")
    print(f"   ‚Ä¢ –†–∞–∑–±—Ä–æ—Å –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏: {saturation_std:.1f}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {'–í—ã—Å–æ–∫–∞—è' if saturation > 100 else '–°—Ä–µ–¥–Ω—è—è' if saturation > 60 else '–ù–∏–∑–∫–∞—è'}")
    
    # 4. –ö–æ—Ä–∏—á–Ω–µ–≤—ã–µ –æ—Ç—Ç–µ–Ω–∫–∏
    brown_mask = (
        (img_array[:,:,0] > img_array[:,:,2]) &
        (img_array[:,:,1] > img_array[:,:,2]) &
        (img_array[:,:,0] < 150) &
        (img_array[:,:,1] < 120)
    )
    brown_ratio = np.sum(brown_mask) / (img_array.shape[0] * img_array.shape[1])
    
    print(f"\\nüü§ –ö–û–†–ò–ß–ù–ï–í–´–ï –û–¢–¢–ï–ù–ö–ò:")
    print(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π: {brown_ratio:.1%}")
    print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π: {np.sum(brown_mask):,} –∏–∑ {img_array.shape[0] * img_array.shape[1]:,}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {'–ú–Ω–æ–≥–æ –≥—Ä—è–∑–∏' if brown_ratio > 0.15 else '–£–º–µ—Ä–µ–Ω–Ω–æ' if brown_ratio > 0.08 else '–ß–∏—Å—Ç–æ'}")
    
    # 5. –ß–µ—Ç–∫–æ—Å—Ç—å –∫—Ä–∞–µ–≤
    edge_image = gray.filter(ImageFilter.FIND_EDGES)
    edge_intensity = np.mean(np.array(edge_image))
    edge_std = np.std(np.array(edge_image))
    
    print(f"\\nüîç –ß–ï–¢–ö–û–°–¢–¨ –ö–†–ê–ï–í:")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –∫—Ä–∞–µ–≤: {edge_intensity:.1f}")
    print(f"   ‚Ä¢ –†–∞–∑–±—Ä–æ—Å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏: {edge_std:.1f}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {'–ß–µ—Ç–∫–∏–µ' if edge_intensity > 25 else '–°—Ä–µ–¥–Ω–∏–µ' if edge_intensity > 15 else '–†–∞–∑–º—ã—Ç—ã–µ'}")
    
    # 6. –Ø—Ä–∫–æ—Å—Ç—å
    brightness = np.mean(img_array)
    brightness_std = np.std(img_array)
    
    print(f"\\nüí° –Ø–†–ö–û–°–¢–¨:")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å: {brightness:.1f}")
    print(f"   ‚Ä¢ –†–∞–∑–±—Ä–æ—Å —è—Ä–∫–æ—Å—Ç–∏: {brightness_std:.1f}")
    print(f"   ‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {'–í—ã—Å–æ–∫–∞—è' if brightness > 110 else '–°—Ä–µ–¥–Ω—è—è' if brightness > 90 else '–ù–∏–∑–∫–∞—è'}")
    
    # –ü–æ–¥—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≥—Ä—è–∑–∏
    print(f"\\nüìä –†–ê–°–ß–ï–¢ –ò–ù–î–ï–ö–°–ê –ì–†–Ø–ó–ò:")
    dirt_score = 0
    
    # –¶–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    if color_diversity < 80:
        score_add = 2
        dirt_score += score_add
        print(f"   üî¥ –û—á–µ–Ω—å –Ω–∏–∑–∫–æ–µ —Ü–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: +{score_add}")
    elif color_diversity < 120:
        score_add = 1
        dirt_score += score_add
        print(f"   üü° –ù–∏–∑–∫–æ–µ —Ü–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: +{score_add}")
    else:
        print(f"   üü¢ –•–æ—Ä–æ—à–µ–µ —Ü–≤–µ—Ç–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: +0")
    
    # –ö–æ–Ω—Ç—Ä–∞—Å—Ç
    if contrast < 25:
        score_add = 2
        dirt_score += score_add
        print(f"   üî¥ –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç: +{score_add}")
    elif contrast < 40:
        score_add = 1
        dirt_score += score_add
        print(f"   üü° –ù–∏–∑–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç: +{score_add}")
    else:
        print(f"   üü¢ –•–æ—Ä–æ—à–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç: +0")
    
    # –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
    if saturation < 60:
        score_add = 1.5
        dirt_score += score_add
        print(f"   üî¥ –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å: +{score_add}")
    elif saturation < 100:
        score_add = 0.5
        dirt_score += score_add
        print(f"   üü° –ù–∏–∑–∫–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å: +{score_add}")
    else:
        print(f"   üü¢ –•–æ—Ä–æ—à–∞—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å: +0")
    
    # –ö–æ—Ä–∏—á–Ω–µ–≤—ã–µ –æ—Ç—Ç–µ–Ω–∫–∏
    if brown_ratio > 0.15:
        score_add = 2
        dirt_score += score_add
        print(f"   üî¥ –ú–Ω–æ–≥–æ –∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤: +{score_add}")
    elif brown_ratio > 0.08:
        score_add = 1
        dirt_score += score_add
        print(f"   üü° –£–º–µ—Ä–µ–Ω–Ω–æ –∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤: +{score_add}")
    else:
        print(f"   üü¢ –ú–∞–ª–æ –∫–æ—Ä–∏—á–Ω–µ–≤—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤: +0")
    
    # –ß–µ—Ç–∫–æ—Å—Ç—å –∫—Ä–∞–µ–≤
    if edge_intensity < 15:
        score_add = 1.5
        dirt_score += score_add
        print(f"   üî¥ –û—á–µ–Ω—å —Ä–∞–∑–º—ã—Ç—ã–µ –∫—Ä–∞—è: +{score_add}")
    elif edge_intensity < 25:
        score_add = 0.5
        dirt_score += score_add
        print(f"   üü° –†–∞–∑–º—ã—Ç—ã–µ –∫—Ä–∞—è: +{score_add}")
    else:
        print(f"   üü¢ –ß–µ—Ç–∫–∏–µ –∫—Ä–∞—è: +0")
    
    # –Ø—Ä–∫–æ—Å—Ç—å
    if brightness < 90:
        score_add = 1
        dirt_score += score_add
        print(f"   üî¥ –ù–∏–∑–∫–∞—è —è—Ä–∫–æ—Å—Ç—å: +{score_add}")
    elif brightness < 110:
        score_add = 0.5
        dirt_score += score_add
        print(f"   üü° –£–º–µ—Ä–µ–Ω–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å: +{score_add}")
    else:
        print(f"   üü¢ –•–æ—Ä–æ—à–∞—è —è—Ä–∫–æ—Å—Ç—å: +0")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    print(f"\\nüèÜ –ò–¢–û–ì–û–í–´–ô –ò–ù–î–ï–ö–° –ì–†–Ø–ó–ò: {dirt_score:.1f}")
    
    if dirt_score >= 6:
        status = "–æ—á–µ–Ω—å –≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü§"
        explanation = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–π–∫–∞"
    elif dirt_score >= 4:
        status = "–≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü´"
        explanation = "–°–∏–ª—å–Ω–æ–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ç—â–∞—Ç–µ–ª—å–Ω–∞—è –º–æ–π–∫–∞"
    elif dirt_score >= 2:
        status = "—Å–ª–µ–≥–∫–∞ –≥—Ä—è–∑–Ω–∞—è"
        emoji = "üü®"
        explanation = "–õ–µ–≥–∫–æ–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ - –æ–±—ã—á–Ω–∞—è –º–æ–π–∫–∞"
    elif dirt_score >= 1:
        status = "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å—Ç–∞—è"
        emoji = "üü©"
        explanation = "–•–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ - –ª–µ–≥–∫–∞—è –æ—á–∏—Å—Ç–∫–∞"
    else:
        status = "–æ—á–µ–Ω—å —á–∏—Å—Ç–∞—è"
        emoji = "‚ú®"
        explanation = "–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã"
    
    print(f"üìã –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: {emoji} {status.upper()}")
    print(f"üí¨ {explanation}")
    print("="*60)
    
    return status, emoji, dirt_score

def load_model(model_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    model = MulticlassDamageModel(num_classes=3)
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –≠–ø–æ—Ö–∞: {checkpoint.get('epoch', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        if 'f1_score' in checkpoint:
            print(f"üìä F1-score –º–æ–¥–µ–ª–∏: {checkpoint['f1_score']:.4f}")
    else:
        model.load_state_dict(checkpoint)
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)")
    
    model.to(device)
    model.eval()
    return model, device

def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)
    
    return image_tensor, image

def predict_damage(model, image_tensor, device):
    class_names = ['no_damage', 'minor_damage', 'major_damage']
    
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        
        outputs = model(image_tensor)
        probabilities = F.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
        
        probs = probabilities.cpu().numpy()[0]
        predicted_class = class_names[predicted.item()]
        confidence_score = confidence.item()
        
        return predicted_class, confidence_score, probs, class_names

def analyze_image_with_dirt_details(image_filename):
    data_folder = r"C:\\Users\\–î–∏–º–∞—à\\Desktop\\python\\hackaton\\data"
    model_path = r"C:\\Users\\–î–∏–º–∞—à\\Desktop\\python\\hackaton\\car_state\\training_results\\finetuned_best_model.pth"
    
    image_path = os.path.join(data_folder, image_filename)
    
    print("üöó –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –∏ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–π")
    print("="*60)
    print(f"üìÇ –ü–∞–ø–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {data_folder}")
    print(f"üñºÔ∏è  –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_filename}")
    
    if not os.path.exists(image_path):
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return
    
    try:
        print("\\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        model, device = load_model(model_path)
        
        print("üñºÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        image_tensor, original_image = preprocess_image(image_path)
        print(f"   –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {original_image.size}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥—Ä—è–∑–∏
        dirt_status, dirt_emoji, dirt_score = analyze_dirt_level_detailed(original_image)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        print("\\nüîç –ê–Ω–∞–ª–∏–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π...")
        predicted_class, confidence, probabilities, class_names = predict_damage(model, image_tensor, device)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        print("\\n" + "="*60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê –ü–û–í–†–ï–ñ–î–ï–ù–ò–ô:")
        print("="*60)
        
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {predicted_class}")
        print(f"üìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}")
        print(f"üßº –ß–∏—Å—Ç–æ—Ç–∞: {dirt_emoji} {dirt_status} (–∏–Ω–¥–µ–∫—Å: {dirt_score:.1f})")
        
        print("\\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
        for name, prob in zip(class_names, probabilities):
            bar_length = int(prob * 30)
            bar = "‚ñà" * bar_length + "‚ñë" * (30 - bar_length)
            
            if name == 'no_damage':
                emoji = "‚úÖ"
            elif name == 'minor_damage':
                emoji = "üîß"
            else:
                emoji = "üö®"
                
            print(f"   {emoji} {name:15}: {prob:.1%} |{bar}|")
        
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
        import traceback
        traceback.print_exc()

def main():
    if len(sys.argv) > 1:
        image_filename = sys.argv[1]
    else:
        image_filename = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ").strip()
        
        if not image_filename:
            print("‚ùå –ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ!")
            return
    
    analyze_image_with_dirt_details(image_filename)

if __name__ == "__main__":
    main()