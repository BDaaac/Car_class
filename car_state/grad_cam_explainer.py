"""
–°–∏—Å—Ç–µ–º–∞ Grad-CAM –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞ –∫–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–º–æ—Ç—Ä–∏—Ç –º–æ–¥–µ–ª—å
"""
import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from pathlib import Path

class GradCAM:
    """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è Grad-CAM –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    
    def __init__(self, model, target_layer=None):
        self.model = model
        self.model.eval()
        
        # –ï—Å–ª–∏ —Å–ª–æ–π –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π conv —Å–ª–æ–π
        if target_layer is None:
            self.target_layer = self.model.backbone.layer4[-1].conv3
        else:
            self.target_layer = target_layer
        
        self.gradients = None
        self.activations = None
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ö—É–∫–∏
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_backward_hook(self.save_gradient)
    
    def save_activation(self, module, input, output):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        self.activations = output
    
    def save_gradient(self, module, grad_input, grad_output):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã"""
        self.gradients = grad_output[0]
    
    def generate_cam(self, input_image, target_class=None):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞—Ä—Ç—É –≤–Ω–∏–º–∞–Ω–∏—è"""
        # Forward pass
        output = self.model(input_image)
        
        if target_class is None:
            target_class = torch.argmax(output, dim=1)
        
        # Backward pass
        self.model.zero_grad()
        class_score = output[:, target_class]
        class_score.backward()
        
        # –ü–æ–ª—É—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        gradients = self.gradients[0]  # [C, H, W]
        activations = self.activations[0]  # [C, H, W]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–∞–∫ —Å—Ä–µ–¥–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        weights = torch.mean(gradients, dim=(1, 2))  # [C]
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π
        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)
        for i, w in enumerate(weights):
            cam += w * activations[i, :, :]
        
        # ReLU
        cam = F.relu(cam)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        cam = cam - cam.min()
        cam = cam / cam.max()
        
        return cam.detach().cpu().numpy()
    
    def visualize_cam(self, original_image, cam, alpha=0.4):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ä—Ç—ã –≤–Ω–∏–º–∞–Ω–∏—è –ø–æ–≤–µ—Ä—Ö –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ numpy –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(original_image, torch.Tensor):
            if original_image.dim() == 4:
                original_image = original_image[0]
            original_image = original_image.permute(1, 2, 0).cpu().numpy()
            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            original_image = original_image * std + mean
            original_image = np.clip(original_image, 0, 1)
        
        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –ø–æ–¥ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        h, w = original_image.shape[:2]
        cam_resized = cv2.resize(cam, (w, h))
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç–æ–≤—É—é –∫–∞—Ä—Ç—É
        heatmap = cm.jet(cam_resized)[:, :, :3]
        
        # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        result = (1 - alpha) * original_image + alpha * heatmap
        result = np.clip(result, 0, 1)
        
        return result, heatmap

class ExplainableAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ —á–µ—Ä–µ–∑ Grad-CAM"""
    
    def __init__(self, model_path, device='cpu'):
        self.device = device
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        from improved_training import ImprovedDamageModel
        self.model = ImprovedDamageModel(num_classes=2)
        
        checkpoint = torch.load(model_path, map_location=device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(device)
        self.model.eval()
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
        self.threshold = checkpoint.get('threshold', 0.5)
        
        # –°–æ–∑–¥–∞–µ–º Grad-CAM
        self.grad_cam = GradCAM(self.model)
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def analyze_with_explanation(self, image_path):
        """–ê–Ω–∞–ª–∏–∑ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ Grad-CAM"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(image_path).convert('RGB')
        original_image = np.array(image)
        
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with torch.no_grad():
            output = self.model(input_tensor)
            probabilities = F.softmax(output, dim=1)
            confidence = probabilities.max().item()
            predicted_class = torch.argmax(probabilities, dim=1).item()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å —É—á–µ—Ç–æ–º –ø–æ—Ä–æ–≥–∞
        damage_prob = probabilities[0, 1].item()
        
        if confidence < 0.7:  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            status = "—Ç—Ä–µ–±—É–µ—Ç_–æ—Å–º–æ—Ç—Ä–∞"
            confidence_level = "–Ω–∏–∑–∫–∞—è"
        elif damage_prob > self.threshold:
            status = "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è_–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"
            confidence_level = "–≤—ã—Å–æ–∫–∞—è" if confidence > 0.85 else "—Å—Ä–µ–¥–Ω—è—è"
        else:
            status = "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è_–Ω–µ_–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"
            confidence_level = "–≤—ã—Å–æ–∫–∞—è" if confidence > 0.85 else "—Å—Ä–µ–¥–Ω—è—è"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Grad-CAM
        cam = self.grad_cam.generate_cam(input_tensor, target_class=predicted_class)
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        explained_image, heatmap = self.grad_cam.visualize_cam(
            original_image, cam, alpha=0.4
        )
        
        return {
            'status': status,
            'confidence': confidence,
            'confidence_level': confidence_level,
            'damage_probability': damage_prob,
            'threshold': self.threshold,
            'explanation': {
                'original_image': original_image,
                'heatmap': heatmap,
                'explained_image': explained_image,
                'attention_map': cam
            },
            'human_readable': self.format_explanation(
                status, confidence, damage_prob, confidence_level
            )
        }
    
    def format_explanation(self, status, confidence, damage_prob, confidence_level):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        status_map = {
            '–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è_–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è',
            '–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è_–Ω–µ_–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã': '–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã',
            '—Ç—Ä–µ–±—É–µ—Ç_–æ—Å–º–æ—Ç—Ä–∞': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Å–º–æ—Ç—Ä'
        }
        
        confidence_map = {
            '–≤—ã—Å–æ–∫–∞—è': '–≤—ã—Å–æ–∫–æ–π',
            '—Å—Ä–µ–¥–Ω—è—è': '—Å—Ä–µ–¥–Ω–µ–π', 
            '–Ω–∏–∑–∫–∞—è': '–Ω–∏–∑–∫–æ–π'
        }
        
        result = f"üîç {status_map[status]} —Å {confidence_map[confidence_level]} —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é ({confidence:.1%})"
        
        if status == '–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è_–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã':
            result += f"\nüö® –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {damage_prob:.1%}"
            result += f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—â–µ—Ä–±–∞"
        elif status == '—Ç—Ä–µ–±—É–µ—Ç_–æ—Å–º–æ—Ç—Ä–∞':
            result += f"\n‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"
            result += f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¢—Ä–µ–±—É–µ—Ç—Å—è –æ—Å–º–æ—Ç—Ä —ç–∫—Å–ø–µ—Ä—Ç–æ–º"
        else:
            result += f"\n‚úÖ –ê–≤—Ç–æ–º–æ–±–∏–ª—å –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏"
        
        return result
    
    def save_explanation(self, analysis_result, save_path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        axes[0].imshow(analysis_result['explanation']['original_image'])
        axes[0].set_title('–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
        axes[0].axis('off')
        
        # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
        axes[1].imshow(analysis_result['explanation']['heatmap'])
        axes[1].set_title('–ö–∞—Ä—Ç–∞ –≤–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏')
        axes[1].axis('off')
        
        # –û–±—ä—è—Å–Ω–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        axes[2].imshow(analysis_result['explanation']['explained_image'])
        axes[2].set_title('–û–±–ª–∞—Å—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏—è')
        axes[2].axis('off')
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        fig.suptitle(analysis_result['human_readable'], fontsize=12, y=0.02)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"üíæ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")

def test_explainable_analyzer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–∏–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    try:
        analyzer = ExplainableAnalyzer('improved_model.pth')
        
        # –ò—â–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        test_image = None
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            images = list(Path('.').glob(ext))
            if images:
                test_image = images[0]
                break
        
        if test_image:
            print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {test_image}")
            
            result = analyzer.analyze_with_explanation(test_image)
            
            print(f"\n{result['human_readable']}")
            print(f"\nüìä –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
            print(f"   –°—Ç–∞—Ç—É—Å: {result['status']}")
            print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.3f}")
            print(f"   –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {result['damage_probability']:.3f}")
            print(f"   –ü–æ—Ä–æ–≥: {result['threshold']:.3f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            analyzer.save_explanation(result, 'explanation_result.png')
            
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    test_explainable_analyzer()