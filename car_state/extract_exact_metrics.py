import torch
import json
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–∏–ª—è
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def extract_metrics_from_checkpoint():
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ checkpoint —Ñ–∞–π–ª–æ–≤"""
    
    print("üîç –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¢–û–ß–ù–´–• –ú–ï–¢–†–ò–ö –ò–ó CHECKPOINT")
    print("=" * 60)
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    models = {
        "Base Model": "training_results/best_model.pth",
        "Fine-tuned Model": "training_results/finetuned_best_model.pth"
    }
    
    results = {}
    
    for model_name, model_path in models.items():
        if Path(model_path).exists():
            print(f"\nüì¶ –ê–Ω–∞–ª–∏–∑: {model_name}")
            print(f"üìÅ –ü—É—Ç—å: {model_path}")
            
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
                file_size = Path(model_path).stat().st_size / (1024 * 1024)
                print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.2f} MB")
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                model_metrics = {}
                
                if isinstance(checkpoint, dict):
                    print(f"üìã –°–æ–¥–µ—Ä–∂–∏–º–æ–µ checkpoint:")
                    for key in checkpoint.keys():
                        print(f"   ‚Ä¢ {key}")
                    
                    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    if 'val_f1' in checkpoint:
                        model_metrics['F1_Score'] = checkpoint['val_f1']
                        print(f"üéØ F1 Score: {checkpoint['val_f1']:.6f}")
                    
                    if 'epoch' in checkpoint:
                        model_metrics['Best_Epoch'] = checkpoint['epoch']
                        print(f"üî¢ –õ—É—á—à–∞—è —ç–ø–æ—Ö–∞: {checkpoint['epoch']}")
                    
                    # –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    if 'val_metrics' in checkpoint:
                        val_metrics = checkpoint['val_metrics']
                        print(f"üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
                        
                        for metric_name, value in val_metrics.items():
                            model_metrics[metric_name] = value
                            if isinstance(value, (int, float)):
                                print(f"   ‚Ä¢ {metric_name}: {value:.4f}")
                            else:
                                print(f"   ‚Ä¢ {metric_name}: {value}")
                
                results[model_name] = model_metrics
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
                results[model_name] = {"error": str(e)}
    
    return results

def create_metrics_visualization(results):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –º–µ—Ç—Ä–∏–∫"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model = None
    best_f1 = 0
    
    for model_name, metrics in results.items():
        if 'F1_Score' in metrics and metrics['F1_Score'] > best_f1:
            best_f1 = metrics['F1_Score']
            best_model = model_name
    
    print(f"\nüèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model}")
    print(f"üéØ –¢–û–ß–ù–ê–Ø F1 SCORE: {best_f1:.6f}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model} (F1={best_f1:.4f})', 
                 fontsize=16, fontweight='bold')
    
    # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1 Score
    ax1 = axes[0, 0]
    model_names = []
    f1_scores = []
    colors = ['#3498db', '#e74c3c']
    
    for i, (model_name, metrics) in enumerate(results.items()):
        if 'F1_Score' in metrics:
            model_names.append(model_name)
            f1_scores.append(metrics['F1_Score'])
    
    if f1_scores:
        bars = ax1.bar(model_names, f1_scores, color=colors[:len(f1_scores)])
        ax1.set_title('F1 Score Comparison', fontweight='bold')
        ax1.set_ylabel('F1 Score')
        ax1.set_ylim(0, 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, score in zip(bars, f1_scores):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
    
    # 2. Improvement Analysis
    ax2 = axes[0, 1]
    if len(f1_scores) == 2:
        improvement = f1_scores[1] - f1_scores[0]
        improvement_pct = (improvement / f1_scores[0]) * 100
        
        categories = ['Base F1', 'Fine-tuned F1', 'Improvement']
        values = [f1_scores[0], f1_scores[1], improvement]
        colors_imp = ['#3498db', '#e74c3c', '#2ecc71']
        
        bars = ax2.bar(categories, values, color=colors_imp)
        ax2.set_title('Performance Improvement', fontweight='bold')
        ax2.set_ylabel('F1 Score / Improvement')
        
        for bar, value in zip(bars, values):
            if value >= 0:
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É–ª—É—á—à–µ–Ω–∏—è
        ax2.text(1, f1_scores[1] + 0.05, f'+{improvement_pct:.1f}%', 
                ha='center', va='bottom', fontsize=12, fontweight='bold', color='green')
    
    # 3. –ú–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    ax3 = axes[1, 0]
    ax3.axis('off')
    
    if best_model and best_model in results:
        metrics_text = f"üìä –î–ï–¢–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò: {best_model}\n\n"
        
        best_metrics = results[best_model]
        for key, value in best_metrics.items():
            if isinstance(value, (int, float)):
                if 'f1' in key.lower() or 'F1' in key:
                    metrics_text += f"üéØ {key}: {value:.6f}\n"
                else:
                    metrics_text += f"üìà {key}: {value:.4f}\n"
            else:
                metrics_text += f"üìù {key}: {value}\n"
        
        ax3.text(0.1, 0.9, metrics_text, fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8),
                transform=ax3.transAxes)
    
    # 4. Progress Timeline
    ax4 = axes[1, 1]
    if len(results) >= 2:
        epochs = []
        f1_progression = []
        
        for model_name, metrics in results.items():
            if 'Best_Epoch' in metrics and 'F1_Score' in metrics:
                epochs.append(metrics['Best_Epoch'])
                f1_progression.append(metrics['F1_Score'])
        
        if len(epochs) >= 2:
            ax4.plot(epochs, f1_progression, 'o-', linewidth=3, markersize=8, 
                    color='#e74c3c', label='F1 Score Progress')
            ax4.set_title('Training Progress', fontweight='bold')
            ax4.set_xlabel('Best Epoch')
            ax4.set_ylabel('F1 Score')
            ax4.grid(True, alpha=0.3)
            ax4.legend()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            for i, (epoch, f1) in enumerate(zip(epochs, f1_progression)):
                model_name = list(results.keys())[i]
                ax4.annotate(f'{model_name}\nF1={f1:.4f}', 
                           (epoch, f1), textcoords="offset points", 
                           xytext=(0,10), ha='center', fontsize=9)
    
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    save_path = 'training_results/best_model_analysis.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nüìä –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {save_path}")
    
    return fig

def save_detailed_report(results):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ JSON"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model = None
    best_f1 = 0
    
    for model_name, metrics in results.items():
        if 'F1_Score' in metrics and metrics['F1_Score'] > best_f1:
            best_f1 = metrics['F1_Score']
            best_model = model_name
    
    report = {
        "analysis_summary": {
            "best_model": best_model,
            "best_f1_score": best_f1,
            "improvement_analysis": {}
        },
        "detailed_metrics": results
    }
    
    # –ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏—è
    if len(results) >= 2:
        models_list = list(results.items())
        if all('F1_Score' in metrics for _, metrics in models_list):
            base_f1 = models_list[0][1]['F1_Score']
            fine_f1 = models_list[1][1]['F1_Score']
            improvement = fine_f1 - base_f1
            improvement_pct = (improvement / base_f1) * 100
            
            report["analysis_summary"]["improvement_analysis"] = {
                "base_f1": base_f1,
                "finetuned_f1": fine_f1,
                "absolute_improvement": improvement,
                "percentage_improvement": improvement_pct
            }
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_path = 'training_results/detailed_model_analysis.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    return report

if __name__ == "__main__":
    try:
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        results = extract_metrics_from_checkpoint()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if results:
            fig = create_metrics_visualization(results)
            plt.show()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report = save_detailed_report(results)
            
            print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
            print("üìä –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –æ—Ç—á–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã")
            
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ checkpoint —Ñ–∞–π–ª–æ–≤")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()